{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "This notebook consolidates all data processing, Similarity computation, and exporting data to website format scripts into a single pipeline:\n",
    "1. Generate and Export sequences from dynamic events for all matches (export_sequences.py)\n",
    "2. Extract ball positions for all sequences (extract_Sequences_ball_postions.py)\n",
    "3. Normalize attacking direction (Positions_Data_converter.py)\n",
    "4. Similarity Score Calculation (Similarity_score.ipynb) \n",
    "5. Export the generated data to the format required by website for visualization (export_data_to_website.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Data directory: d:\\college\\pysport analytics cup\\data\n",
      "Output directory: d:\\college\\pysport analytics cup\\trial_output_json\n",
      "Number of matches to process: 10\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from datetime import datetime\n",
    "# Import helper functions from processing scripts\n",
    "from src.extract_Sequences_ball_positions import  extract_frame_numbers_from_sequence\n",
    "\n",
    "\n",
    "# Configuration\n",
    "MATCH_IDS = [1886347, 1899585, 1925299, 1953632, 1996435, 2006229, 2011166, 2013725, 2015213, 2017461]\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), 'output_json')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Number of matches to process: {len(MATCH_IDS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export Sequences from Dynamic Events for ALL Matches\n",
    "This cell processes dynamic events data and groups them into sequences by team possession for all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_sequences_for_match(match_id):\n",
    "    \"\"\"\n",
    "    Export sequences from dynamic events for a single match.\n",
    "    Returns: (sequences, filtered_dataframe)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Match ID: {match_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load dynamic events data\n",
    "    url = f'https://raw.githubusercontent.com/SkillCorner/opendata/d276a0901fbe80b4790396b9bac93c0bdfaf694a/data/matches/{match_id}/{match_id}_dynamic_events.csv'\n",
    "    local_path = os.path.join(DATA_DIR, f'{match_id}_dynamic_events.csv')\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        print(f'âœ“ Reading events from local file: {local_path}')\n",
    "        de_match = pd.read_csv(local_path)\n",
    "    else:\n",
    "        print(f'âš  Downloading events from URL: {url}')\n",
    "        de_match = pd.read_csv(url)\n",
    "    \n",
    "    # Filter out 'on_ball_engagement' events\n",
    "    filtered_initial = de_match[de_match['event_type'] != 'on_ball_engagement'].copy()\n",
    "    filtered_initial = filtered_initial.sort_values(['frame_start', 'frame_end']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Events after filtering: {len(filtered_initial)}\")\n",
    "    \n",
    "    # Build sequences\n",
    "    sequences = []\n",
    "    current = None\n",
    "    seq_counter = 1\n",
    "    seq_ids = []\n",
    "    included_idx = []\n",
    "    off_run_included = 0\n",
    "    off_run_excluded = 0\n",
    "    \n",
    "    for idx, row in filtered_initial.iterrows():\n",
    "        team = row.get('team_id')\n",
    "        ev_type = row.get('event_type')\n",
    "        event = {\n",
    "            'event_id': row.get('event_id'),\n",
    "            'player_id': row.get('player_id'),\n",
    "            'frame_start': int(row['frame_start']) if not pd.isna(row.get('frame_start')) else None,\n",
    "            'frame_end': int(row['frame_end']) if not pd.isna(row.get('frame_end')) else None,\n",
    "        }\n",
    "        \n",
    "        # Start new sequence if no current sequence\n",
    "        if current is None:\n",
    "            current = {\n",
    "                'sequence_id': seq_counter,\n",
    "                'team_id': team,\n",
    "                'events': [event],\n",
    "                'attacking_side': row.get('attacking_side')\n",
    "            }\n",
    "            seq_ids.append(seq_counter)\n",
    "            included_idx.append(idx)\n",
    "            seq_counter += 1\n",
    "            if ev_type == 'off_ball_run':\n",
    "                off_run_included += 1\n",
    "            continue\n",
    "        \n",
    "        # Handle off_ball_run: include only if same team\n",
    "        if ev_type == 'off_ball_run' and team != current['team_id']:\n",
    "            off_run_excluded += 1\n",
    "            continue\n",
    "        \n",
    "        # Group by team\n",
    "        if team == current['team_id']:\n",
    "            current['events'].append(event)\n",
    "            seq_ids.append(current['sequence_id'])\n",
    "            included_idx.append(idx)\n",
    "            if ev_type == 'off_ball_run':\n",
    "                off_run_included += 1\n",
    "        else:\n",
    "            sequences.append(current)\n",
    "            current = {\n",
    "                'sequence_id': seq_counter,\n",
    "                'team_id': team,\n",
    "                'events': [event],\n",
    "                'attacking_side': row.get('attacking_side')\n",
    "            }\n",
    "            seq_ids.append(seq_counter)\n",
    "            included_idx.append(idx)\n",
    "            seq_counter += 1\n",
    "            if ev_type == 'off_ball_run':\n",
    "                off_run_included += 1\n",
    "    \n",
    "    if current is not None:\n",
    "        sequences.append(current)\n",
    "    \n",
    "    # Attach sequence IDs to filtered dataframe\n",
    "    filtered = filtered_initial.loc[included_idx].copy().reset_index(drop=True)\n",
    "    filtered['sequence_id'] = seq_ids\n",
    "    \n",
    "    # Save sequences to JSON\n",
    "    output_file = os.path.join(OUTPUT_DIR, f'{match_id}_sequences_excluding_offball_onball.json')\n",
    "    with open(output_file, 'w', encoding='utf-8') as fh:\n",
    "        json.dump({'sequences': sequences}, fh, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ Exported {len(sequences)} sequences to {output_file}\")\n",
    "    print(f\"  - Included events: {len(filtered)}\")\n",
    "    print(f\"  - off_ball_run included: {off_run_included}\")\n",
    "    print(f\"  - off_ball_run excluded: {off_run_excluded}\")\n",
    "    \n",
    "    return sequences, filtered\n",
    "\n",
    "# Process ALL matches\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(f\"EXPORTING SEQUENCES FOR ALL {len(MATCH_IDS)} MATCHES\")\n",
    "print(f\"{'#'*60}\\n\")\n",
    "\n",
    "all_matches_sequences = {}\n",
    "all_matches_filtered = {}\n",
    "total_sequences = 0\n",
    "\n",
    "for i, match_id in enumerate(MATCH_IDS, 1):\n",
    "    print(f\"\\n[{i}/{len(MATCH_IDS)}] Processing match {match_id}...\")\n",
    "    try:\n",
    "        sequences, filtered = export_sequences_for_match(match_id)\n",
    "        all_matches_sequences[match_id] = sequences\n",
    "        all_matches_filtered[match_id] = filtered\n",
    "        total_sequences += len(sequences)\n",
    "        print(f\"âœ“ Match {match_id} complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error processing match {match_id}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n\\n{'#'*60}\")\n",
    "print(\"SEQUENCE EXPORT COMPLETE\")\n",
    "print(f\"{'#'*60}\")\n",
    "print(f\"Total matches processed: {len(all_matches_sequences)}\")\n",
    "print(f\"Total sequences exported: {total_sequences}\")\n",
    "print(f\"\\nSample sequence from first match:\")\n",
    "first_match = list(all_matches_sequences.keys())[0]\n",
    "print(json.dumps(all_matches_sequences[first_match][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Ball Positions for ALL Sequences\n",
    "This cell extracts ball position data from tracking URLs for each sequence across all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ball_positions_for_match(match_id, sequences):\n",
    "    \"\"\"\n",
    "    Extract ball positions for all sequences in a match by fetching from URL.\n",
    "    Fetches tracking data ONCE and reuses it for all sequences.\n",
    "    Returns: list of sequence position data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Extracting Ball Positions for Match ID: {match_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Construct tracking URL\n",
    "    tracking_url = f\"https://media.githubusercontent.com/media/SkillCorner/opendata/master/data/matches/{match_id}/{match_id}_tracking_extrapolated.jsonl\"\n",
    "    positions_output_file = os.path.join(OUTPUT_DIR, f'{match_id}_sequences_positions.json')\n",
    "    \n",
    "    print(f\"ðŸ“¡ Fetching tracking data from: {tracking_url}\")\n",
    "    print(f\"â³ This may take a moment (large file)...\")\n",
    "    \n",
    "    # Fetch tracking data ONCE for all sequences\n",
    "    try:\n",
    "        tracking_data = pd.read_json(tracking_url, lines=True)\n",
    "        print(f\"âœ“ Tracking data loaded: {len(tracking_data)} frames\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error fetching tracking data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    all_seq_positions = []\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    for idx, seq in enumerate(sequences):\n",
    "        if not isinstance(seq, dict):\n",
    "            continue\n",
    "        \n",
    "        # Get sequence ID\n",
    "        seq_id = None\n",
    "        for k in ('sequence_id', 'id', 'uid', 'sequenceId'):\n",
    "            if k in seq:\n",
    "                seq_id = seq[k]\n",
    "                break\n",
    "        \n",
    "        if seq_id is None:\n",
    "            print(f\"  âš  Sequence {idx} has no ID, skipping\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Extract frames for this sequence\n",
    "        frames = extract_frame_numbers_from_sequence(seq)\n",
    "        \n",
    "        if not frames:\n",
    "            print(f\"  âš  Sequence {seq_id} has no frames, skipping\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Extract positions from pre-loaded tracking data\n",
    "        positions = extract_positions_from_dataframe(tracking_data, frames)\n",
    "        \n",
    "        # Convert to serializable format\n",
    "        positions_serializable = {str(k): list(v) for k, v in positions.items()}\n",
    "        \n",
    "        # Attach positions to sequence\n",
    "        seq['positions'] = positions_serializable\n",
    "        \n",
    "        # Collect for aggregate file\n",
    "        seq_out = {\n",
    "            'sequence_id': seq_id,\n",
    "            'team_id': seq.get('team_id'),\n",
    "            'frames': frames,\n",
    "            'positions': positions_serializable\n",
    "        }\n",
    "        # Add attacking_side if present in the input sequence\n",
    "        if 'attacking_side' in seq:\n",
    "            seq_out['attacking_side'] = seq['attacking_side']\n",
    "        \n",
    "        all_seq_positions.append(seq_out)\n",
    "        \n",
    "        success_count += 1\n",
    "        \n",
    "        # Progress update every 50 sequences\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(sequences)} sequences...\")\n",
    "    \n",
    "    # Final progress if not already shown\n",
    "    if len(sequences) % 50 != 0:\n",
    "        print(f\"  Processed {len(sequences)}/{len(sequences)} sequences\")\n",
    "    \n",
    "    # Save positions to JSON\n",
    "    output_path = Path(positions_output_file)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as fh:\n",
    "        json.dump({\n",
    "            'total_sequences': len(all_seq_positions),\n",
    "            'sequences': all_seq_positions\n",
    "        }, fh, indent=2)\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved positions for {len(all_seq_positions)} sequences to {positions_output_file}\")\n",
    "    print(f\"  - Success: {success_count}\")\n",
    "    print(f\"  - Failed: {fail_count}\")\n",
    "    \n",
    "    return all_seq_positions\n",
    "\n",
    "\n",
    "def extract_positions_from_dataframe(tracking_df, wanted_frames):\n",
    "    \"\"\"\n",
    "    Extract ball positions from a pre-loaded tracking DataFrame.\n",
    "    Returns: dict frame->(x,y,z) for wanted_frames\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    wanted = set(wanted_frames)\n",
    "    \n",
    "    for _, obj in tracking_df.iterrows():\n",
    "        # Determine frame index\n",
    "        frame = None\n",
    "        for k in ('frame', 'frame_idx', 'frame_index'):\n",
    "            if k in obj and pd.notnull(obj[k]):\n",
    "                try:\n",
    "                    frame = int(obj[k])\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        frame = int(float(obj[k]))\n",
    "                    except Exception:\n",
    "                        frame = None\n",
    "                break\n",
    "        \n",
    "        if frame is None or frame not in wanted:\n",
    "            continue\n",
    "        \n",
    "        # Extract ball positions\n",
    "        bx = by = bz = None\n",
    "        if 'ball_data' in obj and isinstance(obj['ball_data'], dict):\n",
    "            bd = obj['ball_data']\n",
    "            bx = bd.get('x')\n",
    "            by = bd.get('y')\n",
    "            bz = bd.get('z')\n",
    "        elif 'ball' in obj and isinstance(obj['ball'], dict):\n",
    "            b = obj['ball']\n",
    "            bx = b.get('x')\n",
    "            by = b.get('y')\n",
    "            bz = b.get('z')\n",
    "        \n",
    "        # Normalize numeric types\n",
    "        def _safe_float(v):\n",
    "            try:\n",
    "                return None if v is None else float(v)\n",
    "            except Exception:\n",
    "                return None\n",
    "        \n",
    "        bx = _safe_float(bx)\n",
    "        by = _safe_float(by)\n",
    "        bz = _safe_float(bz)\n",
    "        \n",
    "        results[frame] = (bx, by, bz)\n",
    "        \n",
    "        # Early exit if all frames found\n",
    "        if len(results) == len(wanted):\n",
    "            break\n",
    "    \n",
    "    # Mark missing frames explicitly\n",
    "    for f in wanted:\n",
    "        if f not in results:\n",
    "            results[f] = (None, None, None)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Extract ball positions for ALL matches\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(f\"EXTRACTING BALL POSITIONS FOR ALL MATCHES\")\n",
    "print(f\"{'#'*60}\\n\")\n",
    "\n",
    "all_matches_positions = {}\n",
    "total_positions = 0\n",
    "failed_matches = []\n",
    "\n",
    "for i, match_id in enumerate(MATCH_IDS, 1):\n",
    "    print(f\"\\n[{i}/{len(MATCH_IDS)}] Processing match {match_id}...\")\n",
    "    \n",
    "    if match_id not in all_matches_sequences:\n",
    "        print(f\"âš  No sequences found for match {match_id}, skipping positions\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        positions = extract_ball_positions_for_match(match_id, all_matches_sequences[match_id])\n",
    "        \n",
    "        if positions:\n",
    "            all_matches_positions[match_id] = positions\n",
    "            total_positions += len(positions)\n",
    "            print(f\"âœ“ Match {match_id} complete!\")\n",
    "        else:\n",
    "            failed_matches.append(match_id)\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error processing match {match_id}: {str(e)}\")\n",
    "        failed_matches.append(match_id)\n",
    "        continue\n",
    "\n",
    "print(f\"\\n\\n{'#'*60}\")\n",
    "print(\"BALL POSITION EXTRACTION COMPLETE\")\n",
    "print(f\"{'#'*60}\")\n",
    "print(f\"Total matches with positions: {len(all_matches_positions)}\")\n",
    "print(f\"Total sequences with positions: {total_positions}\")\n",
    "print(f\"Failed matches: {len(failed_matches)}\")\n",
    "\n",
    "if failed_matches:\n",
    "    print(f\"\\nFailed matches (tracking data unavailable or error): {failed_matches}\")\n",
    "\n",
    "if all_matches_positions:\n",
    "    print(f\"\\nSample position data from first match:\")\n",
    "    first_match = list(all_matches_positions.keys())[0]\n",
    "    print(json.dumps(all_matches_positions[first_match][0], indent=2)[:800] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert and Normalize Attacking direction for Tracking Data\n",
    "This cell normalizes orientation for all sequences and exports the format required by Similarity Score algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "CONVERTING AND NORMALIZING EVENT DATA\n",
      "############################################################\n",
      "\n",
      "Target events per sequence: 10\n",
      "Output directory: d:\\college\\pysport analytics cup\\trial_output_json\\extracted_sequences\n",
      "\n",
      "Found position files for 1 matches\n",
      "\n",
      "Processing match 1886347...\n",
      "  Found 212 sequences\n",
      "  Extracted sequences: 172\n",
      "Saved frame ranges: d:\\college\\pysport analytics cup\\trial_output_json\\extracted_sequences\\all_matches_10_frame_ranges.csv\n",
      "\n",
      "============================================================\n",
      "Saved combined data: d:\\college\\pysport analytics cup\\trial_output_json\\extracted_sequences\\all_matches_10_positions_normalized.csv\n",
      "Total sequences processed: 212\n",
      "Sequences normalized (flipped): 105\n",
      "Total extracted subsets: 172\n",
      "============================================================\n",
      "\n",
      "âœ“ Event data conversion complete!\n",
      "  Output file: d:\\college\\pysport analytics cup\\trial_output_json\\extracted_sequences\\all_matches_10_positions_normalized.csv\n",
      "\n",
      "Sample of extracted data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "match_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sequence_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "team_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "attacking_side",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "normalized",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "num_positions",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "coordinates_json",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ca7d127d-22ad-4bd9-951f-1b1da29d3038",
       "rows": [
        [
         "0",
         "1886347",
         "6",
         "4177",
         "right_to_left",
         "True",
         "10",
         "[{\"x\": 3.2, \"y\": -21.8, \"z\": 1.69}, {\"x\": 11.87, \"y\": -14.01, \"z\": 1.06}, {\"x\": 11.75, \"y\": -15.8, \"z\": 0.30000000000000004}, {\"x\": 8.11, \"y\": -32.03, \"z\": 0.16}, {\"x\": 7.32, \"y\": -32.33, \"z\": 0.15}, {\"x\": 4.71, \"y\": -32.08, \"z\": 0.16}, {\"x\": -12.36, \"y\": -31.78, \"z\": 0.25}, {\"x\": -10.7, \"y\": -20.36, \"z\": 0.63}, {\"x\": -9.63, \"y\": -20.02, \"z\": 0.56}, {\"x\": -9.26, \"y\": -19.97, \"z\": 0.46}]"
        ],
        [
         "1",
         "1886347",
         "7_subset0",
         "1805",
         "left_to_right",
         "False",
         "10",
         "[{\"x\": 29.1, \"y\": -26.61, \"z\": 0.42}, {\"x\": 29.74, \"y\": -32.68, \"z\": 0.2}, {\"x\": 27.37, \"y\": -24.06, \"z\": 0.52}, {\"x\": 27.28, \"y\": -23.92, \"z\": 0.39}, {\"x\": 11.38, \"y\": -30.43, \"z\": 0.12}, {\"x\": 8.2, \"y\": -27.16, \"z\": 0.22}, {\"x\": 3.56, \"y\": -15.91, \"z\": 0.2}, {\"x\": 3.37, \"y\": -15.11, \"z\": 0.2}, {\"x\": 6.3, \"y\": -11.53, \"z\": 0.22}, {\"x\": 7.26, \"y\": -10.44, \"z\": 0.22}]"
        ],
        [
         "2",
         "1886347",
         "7_subset1",
         "1805",
         "left_to_right",
         "False",
         "10",
         "[{\"x\": 6.74, \"y\": 9.8, \"z\": 0.27}, {\"x\": 6.58, \"y\": 14.59, \"z\": 0.27}, {\"x\": 7.1, \"y\": 15.86, \"z\": 0.28}, {\"x\": 11.73, \"y\": 28.34, \"z\": 0.21}, {\"x\": 7.87, \"y\": 28.78, \"z\": 0.26}, {\"x\": -4.53, \"y\": 19.28, \"z\": 0.32}, {\"x\": -10.61, \"y\": 10.14, \"z\": 0.31}, {\"x\": -16.18, \"y\": -7.13, \"z\": 0.31}, {\"x\": -17.2, \"y\": -10.1, \"z\": 0.28}, {\"x\": -25.84, \"y\": -4.49, \"z\": 0.19}]"
        ],
        [
         "3",
         "1886347",
         "7_subset2",
         "1805",
         "left_to_right",
         "False",
         "10",
         "[{\"x\": -26.05, \"y\": -4.3, \"z\": 0.18}, {\"x\": -26.73, \"y\": -3.94, \"z\": 0.16}, {\"x\": -17.78, \"y\": -10.5, \"z\": 0.19}, {\"x\": -18.85, \"y\": -11.53, \"z\": 0.19}, {\"x\": -20.66, \"y\": -13.08, \"z\": 0.16}, {\"x\": -26.3, \"y\": -21.23, \"z\": 0.1}, {\"x\": -10.12, \"y\": -18.69, \"z\": 0.07}, {\"x\": -8.92, \"y\": -17.62, \"z\": 0.13}, {\"x\": -7.51, \"y\": -16.94, \"z\": 0.47000000000000003}, {\"x\": -5.79, \"y\": -16.75, \"z\": 0.14}]"
        ],
        [
         "4",
         "1886347",
         "13_subset0",
         "1805",
         "left_to_right",
         "False",
         "10",
         "[{\"x\": 27.84, \"y\": 29.25, \"z\": 0.52}, {\"x\": 34.63, \"y\": 31.0, \"z\": 0.35000000000000003}, {\"x\": 32.8, \"y\": 30.8, \"z\": 0.27}, {\"x\": 25.18, \"y\": 32.59, \"z\": 0.27}, {\"x\": 13.73, \"y\": 27.83, \"z\": 0.24}, {\"x\": 13.33, \"y\": 27.68, \"z\": 0.23}, {\"x\": 12.45, \"y\": 27.43, \"z\": 0.23}, {\"x\": 10.72, \"y\": 24.98, \"z\": 0.2}, {\"x\": -0.25, \"y\": 3.24, \"z\": 0.34}, {\"x\": 4.71, \"y\": -11.32, \"z\": 0.36}]"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>attacking_side</th>\n",
       "      <th>normalized</th>\n",
       "      <th>num_positions</th>\n",
       "      <th>coordinates_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1886347</td>\n",
       "      <td>6</td>\n",
       "      <td>4177</td>\n",
       "      <td>right_to_left</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>[{\"x\": 3.2, \"y\": -21.8, \"z\": 1.69}, {\"x\": 11.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset0</td>\n",
       "      <td>1805</td>\n",
       "      <td>left_to_right</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>[{\"x\": 29.1, \"y\": -26.61, \"z\": 0.42}, {\"x\": 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset1</td>\n",
       "      <td>1805</td>\n",
       "      <td>left_to_right</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>[{\"x\": 6.74, \"y\": 9.8, \"z\": 0.27}, {\"x\": 6.58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset2</td>\n",
       "      <td>1805</td>\n",
       "      <td>left_to_right</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>[{\"x\": -26.05, \"y\": -4.3, \"z\": 0.18}, {\"x\": -2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1886347</td>\n",
       "      <td>13_subset0</td>\n",
       "      <td>1805</td>\n",
       "      <td>left_to_right</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>[{\"x\": 27.84, \"y\": 29.25, \"z\": 0.52}, {\"x\": 34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id sequence_id  team_id attacking_side  normalized  num_positions  \\\n",
       "0   1886347           6     4177  right_to_left        True             10   \n",
       "1   1886347   7_subset0     1805  left_to_right       False             10   \n",
       "2   1886347   7_subset1     1805  left_to_right       False             10   \n",
       "3   1886347   7_subset2     1805  left_to_right       False             10   \n",
       "4   1886347  13_subset0     1805  left_to_right       False             10   \n",
       "\n",
       "                                    coordinates_json  \n",
       "0  [{\"x\": 3.2, \"y\": -21.8, \"z\": 1.69}, {\"x\": 11.8...  \n",
       "1  [{\"x\": 29.1, \"y\": -26.61, \"z\": 0.42}, {\"x\": 29...  \n",
       "2  [{\"x\": 6.74, \"y\": 9.8, \"z\": 0.27}, {\"x\": 6.58,...  \n",
       "3  [{\"x\": -26.05, \"y\": -4.3, \"z\": 0.18}, {\"x\": -2...  \n",
       "4  [{\"x\": 27.84, \"y\": 29.25, \"z\": 0.52}, {\"x\": 34...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (172, 7)\n",
      "Columns: ['match_id', 'sequence_id', 'team_id', 'attacking_side', 'normalized', 'num_positions', 'coordinates_json']\n",
      "\n",
      "Frame ranges file created:\n",
      "  Path: d:\\college\\pysport analytics cup\\trial_output_json\\extracted_sequences\\all_matches_10_frame_ranges.csv\n",
      "  Shape: (172, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "match_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sequence_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_frame",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end_frame",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1039a9ce-df93-4b56-bbbc-91a377bdba71",
       "rows": [
        [
         "0",
         "1886347",
         "6",
         "526",
         "755"
        ],
        [
         "1",
         "1886347",
         "7_subset0",
         "990",
         "1161"
        ],
        [
         "2",
         "1886347",
         "7_subset1",
         "1185",
         "1303"
        ],
        [
         "3",
         "1886347",
         "7_subset2",
         "1304",
         "1371"
        ],
        [
         "4",
         "1886347",
         "13_subset0",
         "1731",
         "1845"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1886347</td>\n",
       "      <td>6</td>\n",
       "      <td>526</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset0</td>\n",
       "      <td>990</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset1</td>\n",
       "      <td>1185</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1886347</td>\n",
       "      <td>7_subset2</td>\n",
       "      <td>1304</td>\n",
       "      <td>1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1886347</td>\n",
       "      <td>13_subset0</td>\n",
       "      <td>1731</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id sequence_id  start_frame  end_frame\n",
       "0   1886347           6          526        755\n",
       "1   1886347   7_subset0          990       1161\n",
       "2   1886347   7_subset1         1185       1303\n",
       "3   1886347   7_subset2         1304       1371\n",
       "4   1886347  13_subset0         1731       1845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from src.Positions_Data_converter import (\n",
    "    extract_ball_coordinates\n",
    ")\n",
    "\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(f\"CONVERTING AND NORMALIZING EVENT DATA\")\n",
    "print(f\"{'#'*60}\\n\")\n",
    "\n",
    "# Configuration\n",
    "FIXED_NUM_EVENTS = 10  # Number of events per sequence adjust it if you want to analyze larger/smaller sequences\n",
    "EXTRACTED_DIR = os.path.join(OUTPUT_DIR, 'extracted_sequences')\n",
    "\n",
    "print(f\"Target events per sequence: {FIXED_NUM_EVENTS}\")\n",
    "print(f\"Output directory: {EXTRACTED_DIR}\")\n",
    "\n",
    "\n",
    "position_files_exist = []\n",
    "for match_id in MATCH_IDS:\n",
    "    position_file = os.path.join(OUTPUT_DIR, f'{match_id}_sequences_positions.json')\n",
    "    if os.path.exists(position_file):\n",
    "        position_files_exist.append(str(match_id))\n",
    "\n",
    "print(f\"\\nFound position files for {len(position_files_exist)} matches\")\n",
    "\n",
    "output_csv = extract_ball_coordinates(\n",
    "    match_ids=position_files_exist,\n",
    "    fixed_num_events=FIXED_NUM_EVENTS,\n",
    "    input_dir=OUTPUT_DIR,\n",
    "    output_dir=EXTRACTED_DIR\n",
    ")\n",
    "\n",
    "if output_csv:\n",
    "    print(f\"\\nâœ“ Event data conversion complete!\")\n",
    "    print(f\"  Output file: {output_csv}\")\n",
    "    \n",
    "    # Display sample of extracted data\n",
    "    df_sample = pd.read_csv(output_csv)\n",
    "    print(f\"\\nSample of extracted data:\")\n",
    "    display(df_sample.head())\n",
    "    print(f\"\\nDataset shape: {df_sample.shape}\")\n",
    "    print(f\"Columns: {list(df_sample.columns)}\")\n",
    "    \n",
    "    # Check if frame ranges file was created\n",
    "    frame_range_file = os.path.join(EXTRACTED_DIR, f\"all_matches_{FIXED_NUM_EVENTS}_frame_ranges.csv\")\n",
    "    if os.path.exists(frame_range_file):\n",
    "        df_ranges = pd.read_csv(frame_range_file)\n",
    "        print(f\"\\nFrame ranges file created:\")\n",
    "        print(f\"  Path: {frame_range_file}\")\n",
    "        print(f\"  Shape: {df_ranges.shape}\")\n",
    "        display(df_ranges.head())\n",
    "else:\n",
    "    print(f\"\\nâœ— No data was extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Ball Coordinates\n",
    "\n",
    "This cell loads the extracted ball trajectory data and normalizes all x, y, z coordinates to a [0, 1] range using MinMax scaling.  \n",
    "Normalization ensures that all sequences are on a common scale, which is essential for accurate similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 172 sequences\n",
      "Columns: ['match_id', 'sequence_id', 'team_id', 'attacking_side', 'normalized', 'num_positions', 'coordinates_json']\n",
      "\n",
      "Total coordinates collected: 1720\n",
      "X range: [-52.38, 49.36]\n",
      "Y range: [-34.10, 33.86]\n",
      "Z range: [-0.19, 7.31]\n",
      "\n",
      "Normalization complete!\n",
      "   match_id sequence_id  team_id attacking_side  normalized  num_positions  \\\n",
      "0   1886347           6     4177  right_to_left        True             10   \n",
      "1   1886347   7_subset0     1805  left_to_right       False             10   \n",
      "2   1886347   7_subset1     1805  left_to_right       False             10   \n",
      "3   1886347   7_subset2     1805  left_to_right       False             10   \n",
      "4   1886347  13_subset0     1805  left_to_right       False             10   \n",
      "\n",
      "                                    coordinates_json  \\\n",
      "0  [{\"x\": 3.2, \"y\": -21.8, \"z\": 1.69}, {\"x\": 11.8...   \n",
      "1  [{\"x\": 29.1, \"y\": -26.61, \"z\": 0.42}, {\"x\": 29...   \n",
      "2  [{\"x\": 6.74, \"y\": 9.8, \"z\": 0.27}, {\"x\": 6.58,...   \n",
      "3  [{\"x\": -26.05, \"y\": -4.3, \"z\": 0.18}, {\"x\": -2...   \n",
      "4  [{\"x\": 27.84, \"y\": 29.25, \"z\": 0.52}, {\"x\": 34...   \n",
      "\n",
      "                                         coordinates  \\\n",
      "0  [{'x': 3.2, 'y': -21.8, 'z': 1.69}, {'x': 11.8...   \n",
      "1  [{'x': 29.1, 'y': -26.61, 'z': 0.42}, {'x': 29...   \n",
      "2  [{'x': 6.74, 'y': 9.8, 'z': 0.27}, {'x': 6.58,...   \n",
      "3  [{'x': -26.05, 'y': -4.3, 'z': 0.18}, {'x': -2...   \n",
      "4  [{'x': 27.84, 'y': 29.25, 'z': 0.52}, {'x': 34...   \n",
      "\n",
      "                              normalized_coordinates  \n",
      "0  [{'x': 0.5462944761155888, 'y': 0.180988816951...  \n",
      "1  [{'x': 0.8008649498722233, 'y': 0.110211889346...  \n",
      "2  [{'x': 0.5810890505209357, 'y': 0.645968216597...  \n",
      "3  [{'x': 0.25879693335954396, 'y': 0.43849323131...  \n",
      "4  [{'x': 0.7884804403381167, 'y': 0.932165979988...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    " #Data Loading and Normalization\n",
    "# ============================================================================\n",
    "df = pd.read_csv(output_csv)\n",
    "print(f\"Loaded {len(df)} sequences\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Parse the coordinates_json column\n",
    "df['coordinates'] = df['coordinates_json'].apply(json.loads)\n",
    "\n",
    "# Extract all x, y, z values from all sequences to fit the scaler\n",
    "all_x, all_y, all_z = [], [], []\n",
    "for coords_list in df['coordinates']:\n",
    "    for coord in coords_list:\n",
    "        all_x.append(coord['x'])\n",
    "        all_y.append(coord['y'])\n",
    "        all_z.append(coord.get('z', 0))\n",
    "\n",
    "print(f\"\\nTotal coordinates collected: {len(all_x)}\")\n",
    "print(f\"X range: [{min(all_x):.2f}, {max(all_x):.2f}]\")\n",
    "print(f\"Y range: [{min(all_y):.2f}, {max(all_y):.2f}]\")\n",
    "print(f\"Z range: [{min(all_z):.2f}, {max(all_z):.2f}]\")\n",
    "\n",
    "# Fit scalers on all coordinates\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_z = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(np.array(all_x).reshape(-1, 1))\n",
    "scaler_y.fit(np.array(all_y).reshape(-1, 1))\n",
    "scaler_z.fit(np.array(all_z).reshape(-1, 1))\n",
    "\n",
    "# Normalize each coordinate in each sequence\n",
    "def normalize_coordinates(coords_list):\n",
    "    normalized = []\n",
    "    for coord in coords_list:\n",
    "        norm_coord = {\n",
    "            'x': scaler_x.transform([[coord['x']]])[0][0],\n",
    "            'y': scaler_y.transform([[coord['y']]])[0][0],\n",
    "            'z': scaler_z.transform([[coord.get('z', 0)]])[0][0]\n",
    "        }\n",
    "        normalized.append(norm_coord)\n",
    "    return normalized\n",
    "\n",
    "df['normalized_coordinates'] = df['coordinates'].apply(normalize_coordinates)\n",
    "\n",
    "print(\"\\nNormalization complete!\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the DTW Distance Matrix for Ball Trajectories\n",
    "\n",
    "This cell computes the pairwise similarity between all ball trajectory sequences using Dynamic Time Warping (DTW).  \n",
    "It builds a distance matrix where each entry quantifies how similar two plays are, enabling the identification of similar ball movement patterns across all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    " # DTW Distance Matrix Computation\n",
    "# ============================================================================\n",
    "\n",
    "# Get number of Events dynamically from the data\n",
    "Number_of_events = int(df['num_positions'].iloc[0])\n",
    "print(f\"Number of Events per sequence: {Number_of_events}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create sequence identifiers (matchid_sequenceid)\n",
    "# sequence_id already contains subset info like \"6_subset0\"\n",
    "df['sequence_identifier'] = df['match_id'].astype(str) + '_' + df['sequence_id'].astype(str)\n",
    "\n",
    "# Extract base sequence (remove subset suffix)\n",
    "def get_base_sequence(seq_id):\n",
    "    \"\"\"\n",
    "    Extract base sequence from identifier.\n",
    "    Examples:\n",
    "    - \"1886347_6_subset0\" -> \"1886347_6\"\n",
    "    - \"1886347_6\" -> \"1886347_6\"\n",
    "    \"\"\"\n",
    "    if '_subset' in seq_id:\n",
    "        return seq_id.rsplit('_subset', 1)[0]\n",
    "    return seq_id\n",
    "\n",
    "df['base_sequence'] = df['sequence_identifier'].apply(get_base_sequence)\n",
    "\n",
    "# Convert normalized coordinates to numpy arrays\n",
    "def coords_to_array(coords_list):\n",
    "    return np.array([[c['x'], c['y'], c['z']] for c in coords_list])\n",
    "\n",
    "df['coord_array'] = df['normalized_coordinates'].apply(coords_to_array)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total sequences: {len(df)}\")\n",
    "subset_count = df['sequence_identifier'].str.contains('_subset').sum()\n",
    "unique_bases = df['base_sequence'].nunique()\n",
    "print(f\"Sequences with subsets: {subset_count}\")\n",
    "print(f\"Unique base sequences: {unique_bases}\")\n",
    "print(f\"Average subsets per base: {len(df) / unique_bases:.1f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Prepare data\n",
    "n_sequences = len(df)\n",
    "sequence_ids = df['sequence_identifier'].values\n",
    "coord_arrays = df['coord_array'].values\n",
    "base_sequences = df['base_sequence'].values\n",
    "\n",
    "# Initialize distance matrix with NaN\n",
    "dtw_matrix = np.full((n_sequences, n_sequences), np.nan)\n",
    "\n",
    "print(f\"Computing DTW distances for {n_sequences} sequences...\")\n",
    "total_possible = n_sequences * (n_sequences - 1) // 2\n",
    "print(f\"Total possible comparisons: {total_possible:,}\")\n",
    "\n",
    "# Compute DTW\n",
    "computed = 0\n",
    "skipped = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in range(n_sequences):\n",
    "    if i % 10 == 0 and i > 0:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds()\n",
    "        rate = computed / elapsed if elapsed > 0 else 0\n",
    "        remaining = (total_possible - computed - skipped) / rate if rate > 0 else 0\n",
    "        print(f\"Processing sequence {i+1}/{n_sequences}... (computed: {computed:,}, skipped: {skipped:,}, rate: {rate:.1f}/s, ETA: {remaining/3600:.1f}h)\")\n",
    "    \n",
    "    for j in range(i + 1, n_sequences):\n",
    "        # Skip comparisons between subsets of the same base sequence\n",
    "        if base_sequences[i] == base_sequences[j]:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        # Compute DTW distance\n",
    "        distance, _ = fastdtw(coord_arrays[i], coord_arrays[j], dist=euclidean)\n",
    "        # Normalize by number of positions\n",
    "        dtw_matrix[i, j] = distance / Number_of_events\n",
    "        dtw_matrix[j, i] = distance / Number_of_events\n",
    "        computed += 1\n",
    "\n",
    "# Set diagonal to 0\n",
    "np.fill_diagonal(dtw_matrix, 0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DTW Computation Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Computed: {computed:,}\")\n",
    "print(f\"Skipped: {skipped:,}\")\n",
    "print(f\"Total time: {(datetime.now() - start_time).total_seconds()/3600:.2f} hours\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Create DataFrame\n",
    "dtw_df = pd.DataFrame(dtw_matrix, index=sequence_ids, columns=sequence_ids)\n",
    "print(f\"DTW Matrix shape: {dtw_df.shape}\")\n",
    "\n",
    "# Save DTW distance matrix to CSV\n",
    "output_file = os.path.join(EXTRACTED_DIR, f'dtw_distance_matrix_{Number_of_events}_positions_normalized.csv')\n",
    "dtw_df.to_csv(output_file)\n",
    "print(f\"âœ“ Saved DTW distance matrix to: {output_file}\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\nSample distances (first 5x5):\")\n",
    "print(dtw_df.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Similarity Scores for Website Integration\n",
    "\n",
    "This section exports the top N most similar plays for each match in the format required by the website.  \n",
    "It loads the DTW distance matrix and frame data, ensures all necessary files are available, and saves the results as JSON for direct use in the web application.\n",
    "*Hint it downloads tracking data to extract players postions for each sequence for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Generating Similar Plays JSON for Match 1886347\n",
      "================================================================================\n",
      "Loading DTW matrix from: d:\\college\\pysport analytics cup\\output_json\\extracted_sequences\\dtw_distance_matrix_10_positions_normalized.csv\n",
      "Loading Frames CSV from: d:\\college\\pysport analytics cup\\output_json\\extracted_sequences\\all_matches_10_frame_ranges.csv\n",
      "\n",
      "Found 172 sequences for match 1886347\n",
      "\n",
      "Processing 1886347_6 (Frames: 526-755)...\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1886347_match.json\n",
      "Home Team: Auckland FC (ID: 4177)\n",
      "Away Team: Newcastle United Jets FC (ID: 1805)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1886347_tracking_extrapolated.jsonl\n",
      "Looking for frames between 526 and 755\n",
      "Loaded 230 tracking frames\n",
      "  DEBUG: tracking_df shape = (5060, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                    526\n",
      "x                     -49.46\n",
      "y                       0.53\n",
      "player_id              51009\n",
      "is_detected            False\n",
      "ball_x                  -3.2\n",
      "ball_y                  21.8\n",
      "ball_z                  1.69\n",
      "is_detected_ball        True\n",
      "team_id                 1805\n",
      "short_name          R. Scott\n",
      "number                     1\n",
      "Name: 0, dtype: object\n",
      "  Extracting 230 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [33697, 51713, 163972]\n",
      "    Sample away players: [176224, 51009, 50978]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 230 frames\n",
      "  Loading similar play: 2015213_227_subset2 (Frames: 63430-63492, dist: 0.1066)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\2015213_match.json\n",
      "Home Team: Western United (ID: 1803)\n",
      "Away Team: Auckland FC (ID: 4177)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\2015213_tracking_extrapolated.jsonl\n",
      "Looking for frames between 63430 and 63492\n",
      "Loaded 63 tracking frames\n",
      "  DEBUG: tracking_df shape = (1386, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                    63430\n",
      "x                       -29.67\n",
      "y                        -1.02\n",
      "player_id               285188\n",
      "is_detected              False\n",
      "ball_x                   -5.43\n",
      "ball_y                  -17.59\n",
      "ball_z                    0.21\n",
      "is_detected_ball          True\n",
      "team_id                   4177\n",
      "short_name          A. Paulsen\n",
      "number                      12\n",
      "Name: 0, dtype: object\n",
      "  Extracting 63 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [51008, 809670, 795527]\n",
      "    Sample away players: [51713, 4322, 33697]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 63 frames\n",
      "  Loading similar play: 2013725_12_subset1 (Frames: 8294-8420, dist: 0.1189)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\2013725_match.json\n",
      "Home Team: Western United (ID: 1803)\n",
      "Away Team: Sydney Football Club (ID: 869)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\2013725_tracking_extrapolated.jsonl\n",
      "Looking for frames between 8294 and 8420\n",
      "Loaded 127 tracking frames\n",
      "  DEBUG: tracking_df shape = (2794, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                    8294\n",
      "x                      -49.78\n",
      "y                         1.6\n",
      "player_id              159946\n",
      "is_detected             False\n",
      "ball_x                 -29.92\n",
      "ball_y                  28.49\n",
      "ball_z                   0.08\n",
      "is_detected_ball         True\n",
      "team_id                  1803\n",
      "short_name          M. Sutton\n",
      "number                     33\n",
      "Name: 0, dtype: object\n",
      "  Extracting 127 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [51008, 810406, 809670]\n",
      "    Sample away players: [966307, 1000644, 813317]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 127 frames\n",
      "  Loading similar play: 1925299_115 (Frames: 30808-30886, dist: 0.1257)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1925299_match.json\n",
      "Home Team: Brisbane Roar FC (ID: 1802)\n",
      "Away Team: Perth Glory Football Club (ID: 871)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1925299_tracking_extrapolated.jsonl\n",
      "Looking for frames between 30808 and 30886\n",
      "Loaded 79 tracking frames\n",
      "  DEBUG: tracking_df shape = (1738, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                  30808\n",
      "x                      -27.2\n",
      "y                      -5.45\n",
      "player_id              50999\n",
      "is_detected            False\n",
      "ball_x                 27.24\n",
      "ball_y                -27.07\n",
      "ball_z                  0.48\n",
      "is_detected_ball        True\n",
      "team_id                 1802\n",
      "short_name          M. Freke\n",
      "number                     1\n",
      "Name: 0, dtype: object\n",
      "  Extracting 79 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [965697, 965698, 560898]\n",
      "    Sample away players: [966112, 966113, 966114]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 79 frames\n",
      "  Loading similar play: 1996435_186 (Frames: 47999-48114, dist: 0.1307)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1996435_match.json\n",
      "Home Team: Sydney Football Club (ID: 869)\n",
      "Away Team: Adelaide United Football Club (ID: 866)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1996435_tracking_extrapolated.jsonl\n",
      "Looking for frames between 47999 and 48114\n",
      "Loaded 116 tracking frames\n",
      "  DEBUG: tracking_df shape = (2552, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                47999\n",
      "x                    -40.6\n",
      "y                     5.17\n",
      "player_id           809070\n",
      "is_detected          False\n",
      "ball_x                4.78\n",
      "ball_y               24.03\n",
      "ball_z                1.14\n",
      "is_detected_ball      True\n",
      "team_id                866\n",
      "short_name          E. Cox\n",
      "number                  40\n",
      "Name: 0, dtype: object\n",
      "  Extracting 116 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [966307, 813317, 28293]\n",
      "    Sample away players: [808608, 50949, 51686]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 116 frames\n",
      "  Loading similar play: 1925299_185_subset3 (Frames: 52570-52626, dist: 0.1315)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1925299_match.json\n",
      "Home Team: Brisbane Roar FC (ID: 1802)\n",
      "Away Team: Perth Glory Football Club (ID: 871)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1925299_tracking_extrapolated.jsonl\n",
      "Looking for frames between 52570 and 52626\n",
      "Loaded 57 tracking frames\n",
      "  DEBUG: tracking_df shape = (1254, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                  52570\n",
      "x                     -40.76\n",
      "y                       -3.1\n",
      "player_id              50999\n",
      "is_detected            False\n",
      "ball_x                 -14.9\n",
      "ball_y                -30.11\n",
      "ball_z                  0.09\n",
      "is_detected_ball        True\n",
      "team_id                 1802\n",
      "short_name          M. Freke\n",
      "number                     1\n",
      "Name: 0, dtype: object\n",
      "  Extracting 57 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [965697, 965698, 560898]\n",
      "    Sample away players: [966112, 966113, 966114]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 57 frames\n",
      "  Saved: website\\public\\1886347\\1886347_6.json\n",
      "  Found 5 similar plays\n",
      "\n",
      "Processing 1886347_7_subset0 (Frames: 990-1161)...\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1886347_match.json\n",
      "Home Team: Auckland FC (ID: 4177)\n",
      "Away Team: Newcastle United Jets FC (ID: 1805)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1886347_tracking_extrapolated.jsonl\n",
      "Looking for frames between 990 and 1161\n",
      "Loaded 172 tracking frames\n",
      "  DEBUG: tracking_df shape = (3784, 12)\n",
      "  DEBUG: tracking_df columns = ['frame', 'x', 'y', 'player_id', 'is_detected', 'ball_x', 'ball_y', 'ball_z', 'is_detected_ball', 'team_id', 'short_name', 'number']\n",
      "  DEBUG: First row:\n",
      "frame                    990\n",
      "x                      -25.0\n",
      "y                      -5.75\n",
      "player_id              51009\n",
      "is_detected            False\n",
      "ball_x                  29.1\n",
      "ball_y                -26.61\n",
      "ball_z                  0.42\n",
      "is_detected_ball        True\n",
      "team_id                 1805\n",
      "short_name          R. Scott\n",
      "number                     1\n",
      "Name: 0, dtype: object\n",
      "  Extracting 172 frames...\n",
      "  Home player IDs: 18 | Away player IDs: 18\n",
      "    Sample home players: [33697, 51713, 163972]\n",
      "    Sample away players: [176224, 51009, 50978]\n",
      "    Frame 0: time=0.0, ball=True, home=11, away=11\n",
      "    Frame 1: time=0.1, ball=True, home=11, away=11\n",
      "    Frame 2: time=0.2, ball=True, home=11, away=11\n",
      "  Extracted 172 frames\n",
      "  Loading similar play: 1996435_93 (Frames: 20211-20281, dist: 0.0732)\n",
      "Loading metadata from: D:\\college\\pysport analytics cup\\Data\\1996435_match.json\n",
      "Home Team: Sydney Football Club (ID: 869)\n",
      "Away Team: Adelaide United Football Club (ID: 866)\n",
      "Loading tracking data from: D:\\college\\pysport analytics cup\\Data\\1996435_tracking_extrapolated.jsonl\n",
      "Looking for frames between 20211 and 20281\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     31\u001b[0m frames_lookup \u001b[38;5;241m=\u001b[39m load_frames_lookup(FRAMES_CSV)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# RUN PIPELINE\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mprocess_match_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_match_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_MATCH_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtw_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtw_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframes_lookup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes_lookup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRACKING_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMETADATA_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTOP_N\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\college\\pysport analytics cup\\export_data_to_website.py:309\u001b[0m, in \u001b[0;36mprocess_match_sequences\u001b[1;34m(target_match_id, dtw_matrix, frames_lookup, tracking_dir, metadata_dir, output_dir, top_n)\u001b[0m\n\u001b[0;32m    305\u001b[0m sim_frames \u001b[38;5;241m=\u001b[39m frames_lookup[similar_full_id]\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Loading similar play: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimilar_full_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Frames: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim_frames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msim_frames[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 309\u001b[0m similar_play \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_play_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43msim_match_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_seq_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43msim_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msim_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracking_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtw_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternal_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimilar_full_id\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m similar_play:\n\u001b[0;32m    317\u001b[0m     similar_plays\u001b[38;5;241m.\u001b[39mappend(similar_play)\n",
      "File \u001b[1;32md:\\college\\pysport analytics cup\\export_data_to_website.py:217\u001b[0m, in \u001b[0;36mgenerate_play_data\u001b[1;34m(match_id, sequence_id, start_frame, end_frame, tracking_dir, metadata_dir, is_target, dtw_distance, external_id)\u001b[0m\n\u001b[0;32m    214\u001b[0m     metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayers_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m players_metadata\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Load tracking data directly for the specific frame range\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m tracking_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_tracking_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracking_data:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No tracking data for match \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, sequence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Frames \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_frame\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_frame\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\college\\pysport analytics cup\\Data_visualizer.py:109\u001b[0m, in \u001b[0;36mload_tracking_data\u001b[1;34m(match_id, tracking_dir, min_frame, max_frame)\u001b[0m\n\u001b[0;32m    107\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tracking_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from src.export_data_to_website import (\n",
    "    load_frames_lookup,\n",
    "    load_dtw_matrix,\n",
    "    process_match_sequences\n",
    ")\n",
    "from pathlib import Path\n",
    "import os\n",
    "from src.utility import download_match_files\n",
    "\n",
    "\n",
    "TARGET_MATCH_ID = 1886347 # Change this to the desired match ID you want to find similar plays for\n",
    "TOP_N = 5 # Change this to desired number of similar plays\n",
    "DTW_CSV = os.path.join(EXTRACTED_DIR, f'dtw_distance_matrix_{Number_of_events}_positions_normalized.csv')\n",
    "FRAMES_CSV = os.path.join(EXTRACTED_DIR, f'all_matches_{Number_of_events}_frame_ranges.csv')\n",
    "\n",
    "TRACKING_DIR = r\"./Data\" #If data is already downloaded, specify the path here\n",
    "METADATA_DIR = r\"./Data\"\n",
    "Path(TRACKING_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(METADATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "for match_id in MATCH_IDS:\n",
    "    download_match_files(match_id, TRACKING_DIR, METADATA_DIR)\n",
    "\n",
    "OUTPUT_DIR = Path(rf\"./website/public/{TARGET_MATCH_ID}\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Generating Similar Plays JSON for Match {TARGET_MATCH_ID}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================\n",
    "# LOAD DATA\n",
    "# ============================\n",
    "\n",
    "dtw_matrix = load_dtw_matrix(DTW_CSV)\n",
    "frames_lookup = load_frames_lookup(FRAMES_CSV)\n",
    "\n",
    "# ============================\n",
    "# RUN PIPELINE\n",
    "# ============================\n",
    "\n",
    "process_match_sequences(\n",
    "    target_match_id=TARGET_MATCH_ID,\n",
    "    dtw_matrix=dtw_matrix,\n",
    "    frames_lookup=frames_lookup,\n",
    "    tracking_dir=TRACKING_DIR,\n",
    "    metadata_dir=METADATA_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    top_n=TOP_N\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Done!\")\n",
    "print(f\"JSON files saved to: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
